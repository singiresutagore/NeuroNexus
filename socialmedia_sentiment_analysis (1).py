# -*- coding: utf-8 -*-
"""socialmedia sentiment analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n4Q9QTJyWP1vVcqPHpx4eak31EtBFYVo
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import nltk
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

col_names = ['ID', 'Entity', 'Sentiment', 'text']
ds1=pd.read_csv('/content/drive/MyDrive/twitter_training.csv',names=col_names)
ds2=pd.read_csv('/content/drive/MyDrive/twitter_validation.csv',names=col_names)
ds1.head

ds1.isnull().sum()
ds1.dropna(subset=['text'], inplace=True)

"""** Text Preprocessing**"""

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

ds1['Sentiment'] = ds1['Sentiment'].replace('Irrelevant', 'Neutral')
ds2['Sentiment'] = ds2['Sentiment'].replace('Irrelevant', 'Neutral')

ds1=ds1.drop_duplicates()
ds2=ds2.drop_duplicates()

correlation_matrix = ds1.corr()

# Create a figure and axis for the plot
fig, ax = plt.subplots(figsize=(8, 6))

# Create a heatmap using Matplotlib's matshow
cax = ax.matshow(correlation_matrix, cmap='plasma')

# Add a colorbar
fig.colorbar(cax)

# Set axis labels
ax.set_xticks(np.arange(len(correlation_matrix.columns)))
ax.set_yticks(np.arange(len(correlation_matrix.columns)))
ax.set_xticklabels(correlation_matrix.columns)
ax.set_yticklabels(correlation_matrix.columns)

# Rotate the tick labels and set their alignment
plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")

# Display the plot
plt.title('Correlation Plot')
plt.show()

import re
def clean_text(text):
    text = text.lower()
    text = re.sub(r"https\S+|www\S+https\S+", '',text, flags=re.MULTILINE)
    text = re.sub(r'\@w+|\#','',text)
    text = re.sub(r'[^\w\s]','',text)
    text_tokens = word_tokenize(text)
    filtered_text = [w for w in text_tokens if not w in stop_words]
    return " ".join(filtered_text)

ds1["text"] = ds1['text'].apply(clean_text)
ds2["text"] = ds2['text'].apply(clean_text)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
from collections import Counter
target_cnt = Counter(ds1.Sentiment)
plt.figure(figsize=(16,8))
plt.bar(target_cnt.keys(), target_cnt.values())
plt.title("Dataset labels distribuition")

import plotly.graph_objects as go
sentiment_counts = ds1['Sentiment'].value_counts().sort_index()

sentiment_labels = ['Negative', 'Neutral', 'Positive']
sentiment_colors = ['red', 'grey', 'green']

fig = go.Figure(data=[go.Pie(labels=sentiment_counts.index,
                             values=sentiment_counts.values,
                             textinfo='percent+value+label',
                             marker_colors=sentiment_colors,
                             textposition='auto',
                             hole=.3)])

fig.update_layout(
    title_text='Sentiment Distribution',
    template='plotly_white',
    xaxis=dict(
        title='Sources',
    ),
    yaxis=dict(
        title='Number of Posts in Twitter',
    )
)

fig.update_traces(marker_line_color='black',
                  marker_line_width=1.5,
                  opacity=0.8)

fig.show()

# Check if 'text_lens' is present in the 'train' dataset
if 'text_lens' not in ds1.columns:
    print("The 'text_lens' column is not present in the 'train' dataset.")
else:
    # Create the first boxplot for the 'train' dataset
    sns.boxplot(data=ds1, x='text_lens')
    plt.title("Train dataset")
    plt.show()

# Check if 'text_lens' is present in the 'validation' dataset
if 'text_lens' not in ds2.columns:
    print("The 'text_lens' column is not present in the 'validation' dataset.")
else:
    # Create the second boxplot for the 'validation' dataset
    sns.boxplot(data=ds2, x='text_lens')
    plt.title("Validation dataset")
    plt.show()

tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the number of features
X_train = tfidf_vectorizer.fit_transform(ds1['text'])
y_train = ds1['Sentiment']

X_test = tfidf_vectorizer.transform(ds2['text'])  # Use the same vectorizer for validation
y_test= ds2['Sentiment']

#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Size of x_train:", (X_train.shape))
print("Size of y_train:", (y_train.shape))
print("Size of x_test:", (X_test.shape))
print("Size of y_test:", (y_test.shape))

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)
y_pred=model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-Score: {f1:.2f}")